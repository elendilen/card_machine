import torchaudio
from backend.speaker_identifier import SpeakerIdentifier
from backend.registration import PlayerRegistrar
import whisper
import sounddevice as sd
import numpy as np
from scipy.io.wavfile import write

SAMPLE_FILE = "samples/player2.wav"
TEMP_FILE = "test_temp.wav"
SAMPLERATE = 16000
DURATION = 3  # å½•éŸ³æ—¶é•¿

def record_audio(filename=TEMP_FILE, duration=DURATION):
    print("ğŸ™ï¸ ç°åœ¨è¯·è¯´è¯è¿›è¡Œå®æ—¶è¯†åˆ«æµ‹è¯•...")
    audio = sd.rec(int(SAMPLERATE * duration), samplerate=SAMPLERATE, channels=1, dtype='float32')
    sd.wait()
    write(filename, SAMPLERATE, (audio * 32767).astype(np.int16))
    print("âœ… å½•éŸ³å®Œæˆ")

def main():
    # åˆå§‹åŒ–
    whisper_model = whisper.load_model("medium")
    speaker_identifier = SpeakerIdentifier()
    registrar = PlayerRegistrar()

    # æ³¨å†Œ player1
    waveform, sr = torchaudio.load(SAMPLE_FILE)
    emb = speaker_identifier.extract_embedding(waveform, sr)
    registrar.register("player1", emb)
    print("âœ… æ³¨å†Œ player1 å®Œæˆ")

    # å®æ—¶å½•éŸ³
    record_audio()

    # æå–è¯†åˆ«æ–‡æœ¬
    result = whisper_model.transcribe(TEMP_FILE, language="en", task="transcribe")
    text = result["text"].strip()
    print(f"ğŸ“ Whisperè¯†åˆ«å†…å®¹ï¼š{text}")

    # æå–å½“å‰å£°çº¹ & æ¯”å¯¹
    waveform, sr = torchaudio.load(TEMP_FILE)
    emb = speaker_identifier.extract_embedding(waveform, sr)
    player_id = registrar.match(emb)

    # è¾“å‡ºæ ¼å¼
    if text:
        print(f"\nâœ… è¯†åˆ«ç»“æœï¼šplayer{player_id}: ({text})")
    else:
        print("âš ï¸ æœªè¯†åˆ«å‡ºè¯­éŸ³å†…å®¹")

if __name__ == "__main__":
    main()
